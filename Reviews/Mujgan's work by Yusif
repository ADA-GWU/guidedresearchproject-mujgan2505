Viewer: Yusif Mukhtarov
Submitter: Mujgan Aliyeva
Topic name: User Experience (UX) Evaluation Methods
User Experience (UX) evaluation methods are techniques and approaches used to assess the usability, efficiency, effectiveness, and overall user satisfaction of a product or system. According to ISO 9241- 110:2010 (clause 2.15), user experience is defined as: a personâ€™s perceptions and responses that result from the use and/or anticipated use of a product, system, or service [1]. This formal definition is supplemented by other interpretations: User experience explores how a person feels about using a product, i.e., the experiential, affective, meaningful, and valuable aspects of product use.
Firstly, it is noteworthy that the chosen topic is very crucial since most products are developed for human use, and it is essential to create them in the most comfortable way for human use. However, for getting true, meaningful, and valuable feedback it is required to get involved with as many users as possible to get as much information as we can, and here we face the first problem of collecting, processing, analyzing, and getting valuable insights from such massive dataset. The author suggests a good idea to involve AI technologies, such as natural language processing and machine learning to analyzing user feedback from different sources. The advent of AI approaches brings promising solutions to address the limitations inherent in traditional UX evaluation methods. By leveraging AI technologies, the author can significantly mitigate the issues of time consumption, resource intensity, and the incomplete capture of subjective aspects of user experience as well as bring efficient and accurate evaluation processes.
While the project holds significant interest and importance in its proposal, there is a need to deliberate on the selection of specific techniques. Given the limited timeframe of 11 weeks for the project, it is advisable to carefully choose a subset of techniques or areas to focus on and develop precise user experience (UX) evaluation methods. By narrowing down the project's objectives, it will be possible to achieve greater clarity and effectiveness in its implementation. Here are some commonly used UX evaluation methods to consider:
1. Usability Testing: This involves observing users as they interact with a product or system to identify any usability issues or challenges. Users are given specific tasks to perform, and their interactions, feedback, and behaviors are observed and recorded.
2. Heuristic Evaluation: This method involves users reviewing a product or system based on a set of predefined usability principles or heuristics. The evaluators identify potential usability issues and provide recommendations for improvement.
3. Cognitive Walkthrough: This method involves evaluators simulating the thought processes of users as they interact with a product or system. They analyze the system's interface and assess how easily users can accomplish tasks, focusing on understanding users' goals and decision-making processes.
4. Surveys and Questionnaires: These methods involve gathering user feedback through structured questionnaires or surveys. They can be administered after users have interacted with a product or system to collect their opinions, satisfaction levels, and suggestions for improvement.
5. A/B Testing: This method involves comparing two or more versions of a design or interface to determine which one performs better in terms of user experience and achieving specific goals. Users are randomly assigned to different versions, and their interactions and responses are measured and analyzed.
6. Clickstream Analysis: Clickstream analysis involves analyzing the sequence of user interactions, such as clicks, page views, and navigation patterns, to understand user behavior, identify usability issues, and optimize user flows.
7. Eye Tracking: This method uses eye-tracking technology to measure and analyze where users focus their attention on a product or system. It provides insights into visual attention, information hierarchy, and potential usability issues.
If the primary goal was to develop something completely new, it is highly advisable to carefully select the field of study or, at the very least, identify reliable sources of feedback such as texts, audio recordings, or videos. Furthermore, without specifying particular techniques or areas, it becomes exceedingly challenging to determine the appropriate evaluation metrics for newly developed user experience evaluation methods. This poses significant obstacles in accurately evaluating the final outcomes of the project and monitoring progress. Hence choosing appropriate evaluation technique (which means evaluation metrics for developed UX evaluation methods to assess the effectiveness of those newly developed techniques in analyzing users' feedback) for project after narrowing down research objectives is another piece of advice.
However, the development of something entirely new poses significant challenges when it comes to data collection. The majority of UX evaluation methods rely on user interaction, making it impossible to gather the necessary data for entirely new methods within an 11 week timeframe. Therefore, it is recommended to leverage established UX evaluation techniques that have already amassed data. By identifying specific techniques or areas, it becomes possible to ascertain the accessibility of the required data or, at the very least, estimate the time and resources needed to obtain it. Such an approach enhances project planning accuracy since data collection is a vital component of projects involving AI. Hence choosing appropriate datasets for AI solutions after narrowing down research objectives is another piece of advice.
References
1. (ISO), Author: International Standardization Organization. "Title: ISO DIS 9241-210:2010. Ergonomics of human system interaction - Part 210: Human-centred design for interactive systems (formerly known as 13407)." International Standardization Organization (2010).
